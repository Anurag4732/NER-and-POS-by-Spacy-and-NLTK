{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. POS Tagging:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The university was founded in 1885 by Leland and Jane Stanford in memory of their only child, Leland Stanford Jr., who had died of typhoid fever at age 15 the previous year. Stanford was a former Governor of California and U.S. Senator; he made his fortune as a railroad tycoon. The school admitted its first students on October 1, 1891,[2][3] as a coeducational and non-denominational institution.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk, re, pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "sent1 = 'The university was founded in 1885 by Leland and Jane Stanford in memory of their only child, Leland Stanford Jr., who had died of typhoid fever at age 15 the previous year. Stanford was a former Governor of California and U.S. Senator; he made his fortune as a railroad tycoon. The school admitted its first students on October 1, 1891,[2][3] as a coeducational and non-denominational institution.'\n",
    "sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing:-\n",
    "# sent = ' '.join([word for word in nltk.word_tokenize(re.sub(r'[.,;]', '', sent).replace('[2][3]','')) if word not in stopwords.words('english')])\n",
    "# sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('It', 'PRP'), ('was', 'VBD'), ('founded', 'VBN'), ('in', 'IN'), ('2002', 'CD'), ('by', 'IN'), ('Elon', 'NNP'), ('Musk', 'NNP'), ('with', 'IN'), ('the', 'DT'), ('goal', 'NN'), ('of', 'IN'), ('reducing', 'VBG'), ('space', 'NN'), ('transportation', 'NN'), ('costs', 'NNS'), ('to', 'TO'), ('enable', 'VB'), ('the', 'DT'), ('colonization', 'NN'), ('of', 'IN'), ('Mars', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "sent2 = 'It was founded in 2002 by Elon Musk with the goal of reducing space transportation costs to enable the colonization of Mars'\n",
    "pos_tag = nltk.pos_tag(nltk.word_tokenize(sent2))\n",
    "print(pos_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Find  tag pattern from pos:-\n",
    "1. https://stackoverflow.com/questions/32399299/how-do-i-extract-patterns-from-lists-of-pos-tagged-words-nltk\n",
    "2. https://stackoverflow.com/questions/34672986/detecting-pos-tag-pattern-along-with-specified-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 By particuler tag pattern \n",
    "for it we have to know about the tage pattern for our document and information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['founded in 2002']\n"
     ]
    }
   ],
   "source": [
    "# For three words:-\n",
    "def match(l,p1,p2,p3):\n",
    "    for sub in l:\n",
    "        # avoid index error and catch last three elements\n",
    "        end = len(sub) - 1\n",
    "        for ind, (a, b) in enumerate(sub, 1):\n",
    "            if ind == end:\n",
    "                break\n",
    "            if b == p1 and sub[ind][1] == p2 and sub[ind + 1][1] == p3:\n",
    "                yield (\"{} {} {}\".format(a, sub[ind][0], sub[ind + 1][0]))\n",
    "\n",
    "list_of_pos = [pos_tag]               \n",
    "print(list(match(list_of_pos,\"VBN\",\"IN\", \"CD\")))  ## For year(CD: cardinal digit) of(IN:preposition/subordinating conjunction) establishment(VBD: VERB PAST TENSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "def match(l,p1,p2,p3):\n",
    "    for sub in l:\n",
    "        # avoid index error and catch last three elements\n",
    "        end = len(sub) - 1\n",
    "        for ind, (a, b) in enumerate(sub, 1):\n",
    "            if ind == end:\n",
    "                break\n",
    "            if b == p1 and sub[ind][1] == p2 and sub[ind + 1][1] == p3:\n",
    "                yield (\"{} {} {}\".format(a, sub[ind][0], sub[ind + 1][0]))\n",
    "\n",
    "list_of_pos = [pos_tag]               \n",
    "print(list(match(list_of_pos,\"NNP\",\"CC\",\"NNP\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the goal of', 'the colonization of']\n"
     ]
    }
   ],
   "source": [
    "# For two words:-\n",
    "def match(l,p1,p2):\n",
    "    for sub in l:\n",
    "        # avoid index error and catch last three elements\n",
    "        end = len(sub) - 1\n",
    "        for ind, (a, b) in enumerate(sub, 1):\n",
    "            if ind == end:\n",
    "                break\n",
    "            if b == p1 and sub[ind][1] == p2:\n",
    "                yield (\"{} {} {}\".format(a, sub[ind][0], sub[ind + 1][0]))\n",
    "\n",
    "list_of_pos = [pos_tag]               \n",
    "print(list(match(list_of_pos,\"DT\",\"NN\"))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Triple Method\n",
    "a triple is a set of three entities that codifies a statement about semantic data in the form of subject–predicate[Modifiers]–object\n",
    "expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "founded in 2002 by Elon \n"
     ]
    }
   ],
   "source": [
    "## Who founded the university::-- Who wants a noun in reply and founded is a past verb so VBN\n",
    "##                                reply may be:- founded by ....\n",
    "temp = 0\n",
    "for var in pos_tag: ## It gives the chunk of VBN to NNP\n",
    "    if var[1] == 'VBN' or temp == 1:\n",
    "        print(var[0], end = ' ')\n",
    "        temp = 1\n",
    "        if var[1] == 'NNP':\n",
    "            print()\n",
    "            temp = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Text information extraction and text analysis:-\n",
    "1. https://www.kdnuggets.com/2018/08/named-entity-recognition-practitioners-guide-nlp-4.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>university</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>founded</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  POS\n",
       "0         The   DT\n",
       "1  university   NN\n",
       "2     founded  VBD"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pos_tag, columns = ['word', 'POS'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Stanford</td>\n",
       "      <td>NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Leland</td>\n",
       "      <td>NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>non-denominational</td>\n",
       "      <td>JJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>fortune</td>\n",
       "      <td>JJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>founded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>institution</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>made</td>\n",
       "      <td>VBD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>memory</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  word  POS  freq\n",
       "11            Stanford  NNP     3\n",
       "12                 The   DT     2\n",
       "8               Leland  NNP     2\n",
       "0                    1   CD     1\n",
       "27  non-denominational   JJ     1\n",
       "22             fortune   JJ     1\n",
       "23             founded  VBD     1\n",
       "24         institution   NN     1\n",
       "25                made  VBD     1\n",
       "26              memory   NN     1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Let’s now find out the most frequent named entities in our news corpus\n",
    "df = pd.DataFrame(df.groupby(['word', 'POS']).size()).reset_index().rename(columns = {0:'freq'})\n",
    "df.sort_values(by = 'freq', ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>California</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Governor</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Jane</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Jr</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Leland</td>\n",
       "      <td>NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>October</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Senator</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Stanford</td>\n",
       "      <td>NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>US</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  POS  freq\n",
       "4   California  NNP     1\n",
       "5     Governor  NNP     1\n",
       "6         Jane  NNP     1\n",
       "7           Jr  NNP     1\n",
       "8       Leland  NNP     2\n",
       "9      October  NNP     1\n",
       "10     Senator  NNP     1\n",
       "11    Stanford  NNP     3\n",
       "13          US  NNP     1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most Frequent NNP = singular proper noun \n",
    "#               NNPS = plural proper noun \n",
    "df[(df['POS'] == 'NNP') | (df['POS'] == 'NNPS')]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.NER\n",
    "https://medium.com/greyatom/learning-pos-tagging-chunking-in-nlp-85f7f811a8cb\n",
    "#### 2.1 Noun pharse chunking  https://www.nltk.org/book/ch07.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NP The/DT university/NN)\n",
      "('was', 'VBD')\n",
      "('founded', 'VBN')\n",
      "('in', 'IN')\n",
      "('1885', 'CD')\n",
      "('by', 'IN')\n",
      "('Leland', 'NNP')\n",
      "('and', 'CC')\n",
      "('Jane', 'NNP')\n",
      "('Stanford', 'NNP')\n",
      "('in', 'IN')\n",
      "(NP memory/NN)\n",
      "('of', 'IN')\n",
      "('their', 'PRP$')\n",
      "(NP only/JJ child/NN)\n",
      "(',', ',')\n",
      "('Leland', 'NNP')\n",
      "('Stanford', 'NNP')\n",
      "('Jr.', 'NNP')\n",
      "(',', ',')\n",
      "('who', 'WP')\n",
      "('had', 'VBD')\n",
      "('died', 'VBN')\n",
      "('of', 'IN')\n",
      "(NP typhoid/NN)\n",
      "(NP fever/NN)\n",
      "('at', 'IN')\n",
      "(NP age/NN)\n",
      "('15', 'CD')\n",
      "(NP the/DT previous/JJ year/NN)\n",
      "('.', '.')\n",
      "('Stanford', 'NNP')\n",
      "('was', 'VBD')\n",
      "('a', 'DT')\n",
      "('former', 'JJ')\n",
      "('Governor', 'NNP')\n",
      "('of', 'IN')\n",
      "('California', 'NNP')\n",
      "('and', 'CC')\n",
      "('U.S', 'NNP')\n",
      "('.', '.')\n",
      "('Senator', 'NNP')\n",
      "(';', ':')\n",
      "('he', 'PRP')\n",
      "('made', 'VBD')\n",
      "('his', 'PRP$')\n",
      "(NP fortune/NN)\n",
      "('as', 'IN')\n",
      "(NP a/DT railroad/NN)\n",
      "(NP tycoon/NN)\n",
      "('.', '.')\n",
      "(NP The/DT school/NN)\n",
      "('admitted', 'VBD')\n",
      "('its', 'PRP$')\n",
      "('first', 'JJ')\n",
      "('students', 'NNS')\n",
      "('on', 'IN')\n",
      "('October', 'NNP')\n",
      "('1', 'CD')\n",
      "(',', ',')\n",
      "('1891', 'CD')\n",
      "(',', ',')\n",
      "('[', 'VBD')\n",
      "('2', 'CD')\n",
      "(']', 'NNP')\n",
      "('[', 'VBD')\n",
      "('3', 'CD')\n",
      "(NP ]/NN)\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('coeducational', 'JJ')\n",
      "('and', 'CC')\n",
      "(NP non-denominational/JJ institution/NN)\n",
      "('.', '.')\n"
     ]
    }
   ],
   "source": [
    "# NER:- \n",
    "\n",
    "grammar = ('''NP: {<DT>?<JJ>*<NN>} # NP''')\n",
    "chunk_parser = nltk.RegexpParser(grammar)\n",
    "result = chunk_parser.parse(nltk.pos_tag(nltk.word_tokenize(sent1)))\n",
    "\n",
    "# print(result) # For print like mention in doc as tree\n",
    "for i in result: # For print in a systemtical manner\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Relation extractor:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "\n",
    "def get_continuous_chunks(text):\n",
    "        chunked = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "        continuous_chunk = []\n",
    "        current_chunk = []\n",
    "        for i in chunked:\n",
    "            if type(i) == Tree:\n",
    "                current_chunk.append(\" \".join([token for token, pos in i.leaves()]))\n",
    "            elif current_chunk:\n",
    "                named_entity = \" \".join(current_chunk)\n",
    "                if named_entity not in continuous_chunk:\n",
    "                    continuous_chunk.append(named_entity)\n",
    "                    current_chunk = []\n",
    "            else:\n",
    "                 continue\n",
    "        return continuous_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Leland', 'Jane Stanford', 'Leland Stanford', 'California', 'U.S']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_continuous_chunks(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['European', 'Google', '']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "\n",
    "def get_continuous_chunks(text):\n",
    "    chunked = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "    prev = None\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for i in chunked:\n",
    "        if type(i) == Tree:\n",
    "            current_chunk.append(\" \".join([token for token, pos in i.leaves()]))\n",
    "        elif current_chunk:\n",
    "            named_entity = \" \".join(current_chunk)\n",
    "            if named_entity not in continuous_chunk:\n",
    "                continuous_chunk.append(named_entity)\n",
    "                current_chunk = []\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    if continuous_chunk:\n",
    "        named_entity = \" \".join(current_chunk)\n",
    "        if named_entity not in continuous_chunk:\n",
    "            continuous_chunk.append(named_entity)\n",
    "\n",
    "    return continuous_chunk\n",
    "get_continuous_chunks(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices'\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
